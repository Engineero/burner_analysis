{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import mpl_toolkits.mplot3d as Axes3D\n",
    "\n",
    "from database import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Generate training, testing, and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 42331\n",
      "Keys: ['atmosphericP', 'opPointAct', 'opPointDes', 'temperature', 'staticP', 'dynamicP', 'flameStatus', 'dateTimeStamp']\n",
      "Loading data ................................................... done!\n",
      "Elapsed time: 32.58322612801567 sec\n"
     ]
    }
   ],
   "source": [
    "# Import data from database\n",
    "step = 1/10e3  # microphone sample period, sec\n",
    "mic_list = (\"Ambient\", \"Mic 0\", \"Mic 1\", \"Mic 2\", \"Mic 3\")  # for setting the legend\n",
    "fs = 1/step  # sample rate, Hz\n",
    "\n",
    "# Load data from the database\n",
    "# host = \"mysql.ecn.purdue.edu\"  # 128.46.154.164\n",
    "# user = \"op_point_test\"\n",
    "# database = \"op_point_test\"\n",
    "host = 'localhost'\n",
    "user = 'root'\n",
    "database = 'mysql'\n",
    "table_name = '100_op_point_test'\n",
    "password = 'admin'\n",
    "# with open(\"password.txt\", \"r\") as f:\n",
    "#   password = f.read().rstrip()\n",
    "eng = connect_to_db(host, user, password, database)\n",
    "tic = timeit.default_timer()\n",
    "data = import_data(eng, table_name)\n",
    "toc = timeit.default_timer()\n",
    "if eng.open:\n",
    "    eng.close()\n",
    "print(\"Elapsed time: {} sec\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import processed data from pickle\n",
    "processed_data = []\n",
    "for mic in mic_list:\n",
    "    fname = os.path.join('.', 'Processed', 'short_fft_waterfall_{}.pickle'.format(mic))\n",
    "    processed_data.append(pickle.load(open(fname, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42332, 11), (42332, 501))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "labelset = []\n",
    "for num in range(data['opPointAct'].shape[0]):\n",
    "    start = num*100\n",
    "#     vec = np.concatenate((data['flameStatus'][num], data['opPointAct'][num], data['temperature'][num],\n",
    "    vec = np.concatenate((data['flameStatus'][num], data['opPointAct'][num], data['staticP'][num],\n",
    "                          np.sum([row['res'][num,:] for row in processed_data], axis=1)), axis=0)\n",
    "#                           np.concatenate([row for row in data['dynamicP'][:, start:start+100]])), axis=0)\n",
    "\n",
    "    dataset.append(vec)\n",
    "    vec = np.concatenate((data['flameStatus'][num],\n",
    "                          np.concatenate([row['res'][num,:] for row in processed_data])), axis=0)\n",
    "    labelset.append(vec)\n",
    "dataset = np.array(dataset)\n",
    "labelset = np.array(labelset)\n",
    "dataset.shape, labelset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_size = dataset.shape[1]\n",
    "output_size = labelset.shape[1]\n",
    "num_samples = dataset.shape[0]\n",
    "batch_size = 64\n",
    "num_unrollings = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, data, batch_size, num_unrollings):\n",
    "        self._data = data\n",
    "        self._num_samples = data.shape[0]\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unrollings = num_unrollings\n",
    "        segment = self._num_samples // batch_size\n",
    "        self._offset = 0\n",
    "        self._last_batch = self._next_batch()\n",
    "\n",
    "    def _next_batch(self):\n",
    "        \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "        batch = self._data[self._offset:self._offset+self._batch_size, :]\n",
    "        self._offset += self._batch_size\n",
    "        if self._num_samples - self._offset < self._batch_size:\n",
    "            self._offset = 0\n",
    "        return batch\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "        the last batch of the previous array, followed by num_unrollings new ones.\n",
    "        \"\"\"\n",
    "        batches = [self._last_batch]\n",
    "        for step in range(self._num_unrollings):\n",
    "            batches.append(self._next_batch())\n",
    "        self._last_batch = batches[-1]\n",
    "        return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = np.int(0.85*num_samples)\n",
    "valid_size = len(dataset) - train_size\n",
    "train_batches = BatchGenerator(dataset[:train_size,:], batch_size, num_unrollings)\n",
    "train_label_batches = BatchGenerator(labelset[:train_size,:], batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(dataset[train_size:,:], 1, 1)\n",
    "valid_label_batches = BatchGenerator(labelset[train_size:,:], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "    predictions[predictions < 1e-10] = 1e-10\n",
    "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN Definition\n",
    "\n",
    "Define the long short-term memory (LSTM) recurrent neural network (RNN). Borrowing heavily from the Deep Learning Udacity course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_nodes = 64  #TODO tune this!\n",
    "num_steps = 1001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Parameters\n",
    "    # Combined input, forget, memory cell, and output weights for input and previous state. Also biases.\n",
    "    ifcox = tf.Variable(tf.truncated_normal([input_size, 4*num_nodes], 0.0, 1/np.sqrt(input_size)))\n",
    "    ifcom = tf.Variable(tf.truncated_normal([num_nodes, 4*num_nodes], 0.0, 1/np.sqrt(input_size)))\n",
    "    ifcob = tf.Variable(tf.zeros([1, 4*num_nodes]))\n",
    "    # Variables saving state across unrollings.\n",
    "    saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "    saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "    # Classifier weights and biases.\n",
    "    w = tf.Variable(tf.truncated_normal([num_nodes, output_size], 0.0, 1/np.sqrt(output_size)))\n",
    "    b = tf.Variable(tf.zeros([output_size]))\n",
    "    \n",
    "    # Create saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Definition of the cell computation\n",
    "    def lstm_cell(i, o, state):\n",
    "        \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "        Note that in this formulation, we omit the various connections between the\n",
    "        previous state and the gates.\"\"\"\n",
    "        combined = tf.matmul(i, ifcox) + tf.matmul(o, ifcom) + ifcob\n",
    "        input_gate = tf.sigmoid(combined[:, :num_nodes])\n",
    "        forget_gate = tf.sigmoid(combined[:, num_nodes:2*num_nodes])\n",
    "        update = combined[:, 2*num_nodes:3*num_nodes]\n",
    "        state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "        output_gate = tf.sigmoid(combined[:, 3*num_nodes:])\n",
    "        return output_gate * tf.tanh(state), state\n",
    "    \n",
    "    # Input data\n",
    "    train_data = list()\n",
    "    train_labels = list()\n",
    "    for _ in range(num_unrollings + 1):\n",
    "        train_data.append(tf.placeholder(tf.float32, shape=[batch_size, input_size]))\n",
    "        train_labels.append(tf.placeholder(tf.float32, shape=[batch_size, output_size]))\n",
    "    train_inputs = train_data[:num_unrollings]\n",
    "    train_outputs = train_labels[1:]  # labels are shifted by one time step.\n",
    "    \n",
    "    # Unrolled LSTM loop\n",
    "    outputs = list()\n",
    "    output = saved_output\n",
    "    state = saved_state\n",
    "    for i in train_inputs:\n",
    "        output, state = lstm_cell(i, output, state)\n",
    "        outputs.append(output)\n",
    "    \n",
    "    # Saving state across unrollings\n",
    "    with tf.control_dependencies([saved_output.assign(output),\n",
    "                                  saved_state.assign(state)]):\n",
    "        # Classifier.\n",
    "        logits = tf.nn.xw_plus_b(tf.concat(0, outputs), w, b)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits,\n",
    "                tf.concat(0, train_outputs)))\n",
    "    \n",
    "    # Optimizer\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(10.0, global_step, 2*num_steps//3, 0.1, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "    \n",
    "    # Predictions\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    # Sampling and validation eval: batch 1, no unrolling.\n",
    "    sample_input = tf.placeholder(tf.float32, shape=[1, input_size])\n",
    "    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    reset_sample_state = tf.group(saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "            saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "    sample_output, sample_state = lstm_cell(sample_input, saved_sample_output,\n",
    "            saved_sample_state)\n",
    "    with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                  saved_sample_state.assign(sample_state)]):\n",
    "        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run\n",
    "\n",
    "Train the network on the dataset and observe the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_frequency = 100\n",
    "mean_loss = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized.')\n",
    "    for step in range(num_steps):\n",
    "        # Generate next training batch\n",
    "        batches = train_batches.next()\n",
    "        labels = train_label_batches.next()\n",
    "        \n",
    "        # Generate feed_dict\n",
    "        feed_dict = dict()\n",
    "        for i in range(num_unrollings + 1):\n",
    "            feed_dict[train_data[i]] = batches[i]\n",
    "            feed_dict[train_labels[i]] = labels[i]\n",
    "        _, l, predictions, lr = session.run(\n",
    "                [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "        mean_loss += l\n",
    "        \n",
    "        # Update to the user periodically\n",
    "        if step % summary_frequency == 0:\n",
    "            # Output some information about our training performance\n",
    "            if step > 0:\n",
    "                mean_loss = mean_loss / summary_frequency\n",
    "            # The mean loss is an estimate of the loss over the last few batches.\n",
    "            print('Average loss at step {}: {} learning rate: {}'.format(step, mean_loss, lr))\n",
    "            mean_loss = 0\n",
    "            print('Minibatch perplexity: {}'.format(float(np.exp(logprob(predictions,\n",
    "                    np.concatenate(labels[1:], axis=0))))))\n",
    "\n",
    "    # Measure validation set perplexity.\n",
    "    reset_sample_state.run()\n",
    "    valid_logprob = 0\n",
    "    for num in range(valid_size):\n",
    "        b = valid_batches.next()\n",
    "        l = valid_label_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = valid_logprob + logprob(predictions, l[1])\n",
    "    print('Validation set perplexity: {}'.format(float(np.exp(valid_logprob / valid_size))))\n",
    "    \n",
    "    save_path = saver.save(session, './tmp/model.ckpt')\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "Analyze the performance and see what we can do with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session, './tmp/model.ckpt')\n",
    "    print('Model restored.')\n",
    "    reset_sample_state.run()\n",
    "    valid_logprob = 0\n",
    "    for num in range(10):\n",
    "        b = valid_batches.next()\n",
    "        l = valid_label_batches.next()\n",
    "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "        valid_logprob = logprob(predictions, l[1])\n",
    "        print('Logprob prediction accuracy: {}'.format(np.exp(valid_logprob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering of dataset\n",
    "\n",
    "Attempt to divide the data into `n` seperable clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403, 1004, 1310, 1711, 2919, 4018, 4523, 5524, 6225, 7226, 7527, 8766, 9967, 10506, 12018, 13219, 13922, 14447, 14453, 15045, 15046, 16039, 17120, 19823, 20324, 20330, 20742, 21487, 22683, 23789, 24305, 24807, 25495, 26014, 27343, 28557, 28864, 29743, 30096, 30798, 32015, 32221, 33522, 33723, 35035, 35446, 36522, 37428, 37742, 38451, 38903, 39704, 39705, 40212, 40213, 40219, 41358]\n"
     ]
    }
   ],
   "source": [
    "blow_outs = [ind for ind in range(num_samples) if dataset[ind, 0] == 0]\n",
    "print(blow_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_samples = 1000\n",
    "num_samples = dataset.shape[0]\n",
    "\n",
    "def configure_kmeans(num_clusters):\n",
    "    def choose_random_centroids(samples, num_clusters):\n",
    "        # Step 0: Initialisation: Select `n_clusters` number of random points\n",
    "        random_indices = tf.random_shuffle(tf.range(0, num_samples))\n",
    "        begin = [0,]\n",
    "        size = [num_clusters,]\n",
    "        size[0] = num_clusters\n",
    "        centroid_indices = tf.slice(random_indices, begin, size)\n",
    "        initial_centroids = tf.gather(samples, centroid_indices)\n",
    "        return initial_centroids\n",
    "\n",
    "    points = tf.constant(dataset[:num_samples])\n",
    "    cluster_assignments = tf.Variable(tf.zeros([num_samples], dtype=tf.int64))\n",
    "\n",
    "    # Silly initialization:  Use the first K points as the starting\n",
    "    # centroids.  In the real world, do this better.\n",
    "    centroids = tf.Variable(choose_random_centroids(points, num_clusters))\n",
    "\n",
    "    # Replicate to N copies of each centroid and K copies of each\n",
    "    # point, then subtract and compute the sum of squared distances.\n",
    "    rep_centroids = tf.reshape(tf.tile(centroids, [num_samples, 1]), [num_samples, num_clusters, input_size])\n",
    "    rep_points = tf.reshape(tf.tile(points, [1, num_clusters]), [num_samples, num_clusters, input_size])\n",
    "\n",
    "    #TODO modify the cost function for k-means clustering.\n",
    "    sum_squares = tf.reduce_sum(tf.square(rep_points - rep_centroids),\n",
    "                                reduction_indices=2)\n",
    "\n",
    "    # Use argmin to select the lowest-distance point\n",
    "    best_centroids = tf.argmin(sum_squares, 1)\n",
    "    did_assignments_change = tf.reduce_any(tf.not_equal(best_centroids, \n",
    "                                                        cluster_assignments))\n",
    "\n",
    "    def bucket_mean(data, bucket_ids, num_buckets):\n",
    "        total = tf.unsorted_segment_sum(data, bucket_ids, num_buckets)\n",
    "        count = tf.unsorted_segment_sum(tf.ones_like(data), bucket_ids, num_buckets)\n",
    "        return total / count\n",
    "\n",
    "    means = bucket_mean(points, best_centroids, num_clusters)\n",
    "\n",
    "    # Do not write to the assigned clusters variable until after\n",
    "    # computing whether the assignments have changed - hence with_dependencies\n",
    "    with tf.control_dependencies([did_assignments_change]):\n",
    "        do_updates = tf.group(\n",
    "            centroids.assign(means),\n",
    "            cluster_assignments.assign(best_centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working ......... done!\n",
      "Found in 2.746414817025652 seconds 18 iterations\n",
      "Centroids:\n",
      "[[  9.96938065e-01   2.77444685e+00   1.49156589e+00   1.56837821e+00\n",
      "    9.31021181e-01   2.76599121e+00   1.38914030e-04   1.39178776e-04\n",
      "    1.39178812e-04   1.39178832e-04   1.39178752e-04]\n",
      " [  9.97766860e-01   1.57061957e+00   9.84775647e-02   1.01027822e+00\n",
      "    1.31353030e+00   2.57201901e+00   1.56940269e-07   3.60386116e-14\n",
      "    2.07454961e-14   4.23981200e-15   1.70869745e-11]\n",
      " [  9.98940927e-01   1.42439271e+00   9.03235507e-01   9.17238897e-01\n",
      "    5.16061334e-01   2.55517494e+00   4.81250452e-09   4.70089025e-11\n",
      "    3.67898161e-11   1.64628280e-11   8.32986027e-11]\n",
      " [  9.99278337e-01   1.06603102e+00   1.54763318e-01   1.69489035e+00\n",
      "    3.05379871e-01   2.52414439e+00   5.23070161e-08   4.26334737e-13\n",
      "    1.19921140e-13   2.22613278e-14   2.71405263e-12]]\n",
      "Cluster assignments:  [3 3 3 ..., 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "max_iters = 100  # stop criterion for k-means algorithm\n",
    "progress = np.int(max_iters/50)\n",
    "num_clusters = 4  # blowout, attached, detached, going unstable\n",
    "\n",
    "configure_kmeans(num_clusters)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('Working ', end='', flush=True)\n",
    "    tic = timeit.default_timer()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    changed = True\n",
    "    iters = 0\n",
    "    mean_history = []\n",
    "    \n",
    "    # Run k-means loop\n",
    "    while changed and iters < max_iters:\n",
    "        if iters % progress == 0:\n",
    "            print('.', end='', flush=True)\n",
    "        iters += 1\n",
    "        [changed, _] = sess.run([did_assignments_change, do_updates])\n",
    "        mean_history.append(sum_squares.eval())\n",
    "    print(' done!')\n",
    "    \n",
    "    # Output the results\n",
    "    [centers, assignments] = sess.run([centroids, cluster_assignments])\n",
    "    toc = timeit.default_timer()\n",
    "    print(\"Found in {} seconds {} iterations\".format(toc-tic, iters))\n",
    "    print(\"Centroids:\")\n",
    "    print(centers)\n",
    "    print(\"Cluster assignments: \", assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.44546768  1.69499691  1.60835759  1.7732689 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAEACAYAAABYuJDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125cd3d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.mean(mean_history[0], axis=0))\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(assignments)\n",
    "plt.vlines(blow_outs, -1, num_clusters+1)\n",
    "plt.ylim((-1, num_clusters+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO plot the total average distance to nearest centroid vs. number of centroids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
